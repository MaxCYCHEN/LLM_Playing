{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff15b55d-9e4a-4707-a772-ddfeda129b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import Language\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "import os\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from huggingface_hub import notebook_login\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import textwrap\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019ed17e-784a-4ad2-a661-da2f0bba7e48",
   "metadata": {},
   "source": [
    "## RetrievalQA & Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abaf1b50-c73d-45d0-91bd-f3c69f44961a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Load the embedding model =====\n",
      "===== Build FAISS =====\n"
     ]
    }
   ],
   "source": [
    "#input_doc_pth = r'D:\\nu_QA_data\\m460bsp_Library_StdDriver_headers_1000'\n",
    "#input_doc_pth = r'D:\\nu_QA_data\\m460bsp_StdDriver'\n",
    "#input_doc_pth = r'D:\\nu_QA_data\\m2351bsp_1000'\n",
    "#input_doc_pth = r'D:\\nu_QA_data\\m2351bsp_StdDriver_regs_1000'\n",
    "#input_doc_pth = r'D:\\nu_QA_data\\m251bsp_StdDriver_1000'\n",
    "input_doc_pth = r'D:\\nu_QA_data\\m251bsp_partial'\n",
    "# load embedding model\n",
    "print(\"===== Load the embedding model =====\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',model_kwargs={'device': 'cpu'})\n",
    "\n",
    "# Create vectors store\n",
    "print(\"===== Build FAISS =====\")\n",
    "#vectorstore=FAISS.from_documents(texts, embeddings)\n",
    "vectorstore=FAISS.load_local(input_doc_pth, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6bfc213-8a0e-4c1f-b2d3-23eef5dd2ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin C:\\ProgramData\\anaconda3\\envs\\llama\\Lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.dll\n",
      "CUDA SETUP: CUDA runtime path found: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\bin\\cudart64_110.dll\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary C:\\ProgramData\\anaconda3\\envs\\llama\\Lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.dll...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\llama\\Lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:156: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {WindowsPath('C:/ProgramData/anaconda3/envs/llama/bin')}\n",
      "  warn(msg)\n",
      "C:\\ProgramData\\anaconda3\\envs\\llama\\Lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:156: UserWarning: C:\\ProgramData\\anaconda3\\envs\\llama did not contain ['cudart64_110.dll', 'cudart64_120.dll', 'cudart64_12.dll'] as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979796d9ff1a48bfb781fd2089b42085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# From local location\n",
    "#loc = r'C:\\Users\\USER\\Desktop\\llma\\text-generation-webui\\models\\stabilityai_StableBeluga-7B'\n",
    "#loc = r'C:\\Users\\USER\\Desktop\\llma\\text-generation-webui\\models\\Llama-2-7b-chat-hf'\n",
    "#loc = r'meta-llama/Llama-2-7b-hf'\n",
    "#loc = r'C:\\Users\\USER\\Desktop\\llma\\text-generation-webui\\models\\togethercomputer_LLaMA-2-7B-32K'\n",
    "#loc = r'meta-llama/Llama-2-13b-chat-hf'\n",
    "#loc = r'C:\\Users\\USER\\Desktop\\llma\\text-generation-webui\\models\\Llama-2-7B-32K-Instruct'  #Bad\n",
    "#loc = r'D:\\stablecode-completion-alpha-3b-4k'\n",
    "#loc = r'D:\\codegen25-7b-multi'\n",
    "#loc = r'D:\\codegen25-7b-multi'\n",
    "#loc = r'D:\\CodeLlama-7b-hf'\n",
    "#loc = r'D:\\CodeLlama-7b-Instruct-hf'\n",
    "loc = r'C:\\Users\\USER\\Desktop\\llma\\text-generation-webui\\models\\CodeLlama-34b-Instruct-hf'\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(loc)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    loc, device_map=\"auto\",\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(loc, trust_remote_code=True)\n",
    "#model = AutoModelForCausalLM.from_pretrained(loc, device_map='auto',\n",
    "#                       torch_dtype=torch.float16,\n",
    "#                       use_auth_token=True,\n",
    "#                       trust_remote_code=True,                      \n",
    "#                       #load_in_8bit=True,\n",
    "#                        #load_in_4bit=True\n",
    "#                       )\n",
    "\n",
    "#pipe = pipeline(\n",
    "#         \"text-generation\",\n",
    "#         #\"question-answering\",\n",
    "#         model=model,\n",
    "#         tokenizer= tokenizer,\n",
    "#         torch_dtype=torch.bfloat16,\n",
    "#         device_map=\"auto\",\n",
    "#         max_new_tokens = 1024,\n",
    "#         do_sample=True,\n",
    "#         top_k=10,\n",
    "#         num_return_sequences=1,\n",
    "#         eos_token_id=tokenizer.eos_token_id\n",
    "#         )\n",
    "\n",
    "# code llama\n",
    "pipe = pipeline(\n",
    "         \"text-generation\",\n",
    "         #\"question-answering\",\n",
    "         model=model,\n",
    "         tokenizer= tokenizer,\n",
    "         torch_dtype=torch.bfloat16,\n",
    "         device_map=\"auto\",\n",
    "         max_new_tokens = 4096,\n",
    "         #max_length=500,\n",
    "         do_sample=True,\n",
    "         top_k=10,\n",
    "         top_p=0.9,\n",
    "         temperature=0.1,\n",
    "         num_return_sequences=1,\n",
    "         eos_token_id=tokenizer.eos_token_id\n",
    "         )\n",
    "\n",
    "#pipe = pipeline(\n",
    "#    text-generation\",\n",
    "#         #\"question-answering\",\n",
    "#    model=model,\n",
    "#    tokenizer= tokenizer,\n",
    "#    do_sample=True,\n",
    "#    top_k=10,\n",
    "#    temperature=0.1,\n",
    "#    top_p=0.95,\n",
    "#    num_return_sequences=1,\n",
    "#    eos_token_id=tokenizer.eos_token_id,\n",
    "#    max_length=200,\n",
    "#)\n",
    "\n",
    "llm=HuggingFacePipeline(pipeline=pipe, model_kwargs={'temperature':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04ff4e2-1a10-41ee-8a5f-20ae24e4edc6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c752580-59d1-4400-be59-11f11093cea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# Prompt\n",
    "#template=\"\"\"Use the following pieces of context to answer the question at the end.\n",
    "#Please answer with C Code function as complete as possible.\n",
    "#If you don't know the answer or the question has nothing to do with code or programing, don't try to make up an answer.\n",
    "#{context}\n",
    "#Question: {question}\n",
    "#Answer:\"\"\"\n",
    "\n",
    "# Prompt\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "system_template = \"\"\"You will use the provided context to answer the user questions.\n",
    "Read the given context before answering with C Code function as complete as possible.\n",
    "\"\"\"\n",
    "instruction =\"\"\"\n",
    "context: {context}\n",
    "User: {question}\"\"\"\n",
    "\n",
    "def prompt_format(instruction= instruction, system_template= system_template):\n",
    "    SYSTEM_PROMPT = B_SYS + system_template + E_SYS\n",
    "    prompt_templte = B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "    return prompt_templte\n",
    "template=prompt_format()\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"], template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415b4fab-83d4-4ac6-a13d-8d4ebb0f1eec",
   "metadata": {},
   "source": [
    "## RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d5c00d0-e921-460e-af0c-8283d22b0208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", return_source_documents=True, retriever=vectorstore.as_retriever(), chain_type_kwargs={\n",
    "        \"prompt\": PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "        ),\n",
    "    })\n",
    "\n",
    "#chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", return_source_documents=True, retriever=vectorstore.as_retriever(\n",
    "#    search_type=\"mmr\", # Also test \"similarity\"\n",
    "#    search_kwargs={\"k\": 8}), \n",
    "#    chain_type_kwargs={\n",
    "#        \"prompt\": PromptTemplate(\n",
    "#            template=prompt_format(),\n",
    "#            input_variables=[\"context\", \"question\"],\n",
    "#        ),\n",
    "#    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b8410b6-8212-4cb1-9124-3321ed8f8861",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "#query = \"Write a C code function that reverse a string, input a string in parameter and return the reversed string\"\n",
    "\n",
    "#query = \"Write a C code that BMC data transfer with PDMA\"\n",
    "#query = \"Write a C code of ACMP comparing DAC output with ACMP1_P1\"\n",
    "query = \"Generate a C source code to get data from UART, PDMA to memory address 0x20000000, and do CRC32 at 0x20000000\"\n",
    "#query = \"Write an example C code of configure BMC\"\n",
    "\n",
    "#query = \"Generate a C source code which open EBI with bank2, 16BIT width, and fast timing\"\n",
    "#query = \"Generate a C source code which TIMER0 MODE is TIMER_ONESHOT_MODE, TIMER0_FREQ is 1000000, TIMER0_PRESCALE_VALUE is 5, TIMER0_CMP_VALUE is 0x5A5A5A\"\n",
    "result=chain({\"query\": query}, return_only_outputs=True)\n",
    "#wrapped_text = textwrap.fill(result['result'], width=500)\n",
    "#print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "710841f4-361b-42db-ad08-0e4cf71adb06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'D:\\\\nu_QA_data\\\\m251bsp_partial_source\\\\CRC_CRC32\\\\main.c', 'language': <Language.C: 'c'>}\n",
      "{'source': 'D:\\\\nu_QA_data\\\\m251bsp_partial_source\\\\CRC_CRC32\\\\main.c', 'language': <Language.C: 'c'>}\n",
      "{'source': 'D:\\\\nu_QA_data\\\\m251bsp_partial_source\\\\UART_PDMA\\\\main.c', 'language': <Language.C: 'c'>}\n",
      "{'source': 'D:\\\\nu_QA_data\\\\m251bsp_partial_source\\\\crc.h', 'language': <Language.C: 'c'>}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(result['source_documents'])):\n",
    "    print(result['source_documents'][i].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19c2a19a-3d63-4801-88e1-0c257f274c31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Here is a C source code that performs the described operations:\n",
      "```c\n",
      "#include <stdio.h>\n",
      "#include <string.h>\n",
      "#include \"sys.h\"\n",
      "#include \"uart.h\"\n",
      "#include \"pdma.h\"\n",
      "#include \"crc.h\"\n",
      "\n",
      "#define PDMA_TEST_LENGTH  1024\n",
      "#define PDMA_TEST_ADDRESS 0x20000000\n",
      "\n",
      "volatile uint32_t g_au8RxBuffer[PDMA_TEST_LENGTH];\n",
      "\n",
      "void UART1_IRQHandler(void)\n",
      "{\n",
      "    uint8_t u8InChar;\n",
      "    uint32_t u32Address;\n",
      "    uint32_t u32Size;\n",
      "    uint32_t u32FMCChecksum, u32CRC32Checksum, u32PDMAChecksum;\n",
      "\n",
      "    /* Get the address and size of the data to be transferred */\n",
      "    u32Address = PDMA_TEST_ADDRESS;\n",
      "    u32Size = PDMA_TEST_LENGTH;\n",
      "\n",
      "    /* Disable CRC function */\n",
      "    CRC->CTL = 0;\n",
      "\n",
      "    /* Enable PDMA module clock */\n",
      "    CLK->AHBCLK |= CLK_AHBCLK_PDMACKEN_Msk;\n",
      "\n",
      "    /* Give valid source address and transfer count and program PDMA memory to memory, dest => CRC_WDATA */\n",
      "    PDMA->CHCTL = (1 << 0); // use PDMA CH0\n",
      "    DMA_DESC[0].ctl =\n",
      "        (1 << PDMA_DSCT_CTL_OPMODE_Pos)  | (0 << PDMA_DSCT_CTL_TXTYPE_Pos) |\n",
      "        (7 << PDMA_DSCT_CTL_BURSIZE_Pos) |\n",
      "        (0 << PDMA_DSCT_CTL_SAINC_Pos)   | (3 << PDdic_DESC[0].ctl =\n",
      "        (1 << PDMA_DSCT_CTL_DAINC_Pos) |\n",
      "        (2 << PDMA_DSCT_CTL_TXWIDTH_Pos) | (((u32Size / 4) - 1) << PDMA_DSCT_CTL_TXCNT_Pos);\n",
      "    DMA_DESC[0].src = (uint32_t)u32Address;\n",
      "    DMA_DESC[0].dest = (uint32_t) & (CRC->DAT);\n",
      "    DMA_DESC[0].offset = 0;\n",
      "\n",
      "    PDMA->DSCT[0].CTL = PDMA_OP_SCATTER;\n",
      "    PDMA->DSCT[0].NEXT = (uint32_t)&DMA_DESC[0] - (PDMA->SCATBA);\n",
      "\n",
      "    status = PDMA->INTSTS;\n",
      "    PDMA->INTSTS = status;\n",
      "    PDMA->INTEN = (1 << 0);\n",
      "\n",
      "    /* Trigger PDMA CH0 transfer... */\n",
      "    PDMA->SWREQ = (1 << 0);\n",
      "\n",
      "    for (u32LenCnt = 0; u32LenCnt < PDMA_TEST_LENGTH; u32LenCnt++)\n",
      "    {\n",
      "        if (g_au8RxBuffer[u32LenCnt]!= u32LenCnt)\n",
      "        {\n",
      "            printf(\"\\n Receive Data Compare Error!!\");\n",
      "\n",
      "            while (1);\n",
      "        }\n",
      "\n",
      "        g_au8RxBuffer[u32LenCnt] = 0xff;\n",
      "    }\n",
      "\n",
      "    printf(\"\\nUART PDMA test Pass.\\n\");\n",
      "}\n",
      "\n",
      "int main(void)\n",
      "{\n",
      "    uint32_t u32FMCChecksum, u32CRC32Checksum, u32PDMAChecksum;\n",
      "\n",
      "    /* Unlock protected registers */\n",
      "    SYS_UnlockReg();\n",
      "\n",
      "    /* Init System, peripheral clock and multi-function I/O */\n",
      "    SYS_Init();\n",
      "\n",
      "    /* Init UART0 for printf */\n",
      "    UART0_Init();\n",
      "\n",
      "    size = 1024 * 2;\n",
      "\n",
      "    printf(\"\\n\\nCPU @ %d Hz\\n\", SystemCoreClock);\n",
      "    printf(\"+-----------------------------------------------------+\\n\");\n",
      "    printf(\"|    CRC32 with PDMA Sample Code                      |\\n\");\n",
      "    printf(\"|       - Get APROM first %u bytes CRC result by    |\\n\", size);\n",
      "    printf(\"|          a.) FMC checksum command                   |\\n\");\n",
      "    printf(\"|          b.) CPU write CRC data register directly   |\\n\");\n",
      "    printf(\"|          c.) PDMA write CRC data register           |\\n\");\n",
      "    printf(\"+-----------------------------------------------------+\\n\\n\");\n",
      "\n",
      "    /* Disable CRC function */\n",
      "    CRC->CTL = 0;\n",
      "\n",
      "    /* Enable PDMA module clock */\n",
      "    CLK->AHBCLK |= CLK_AHBCLK_PDMACKEN_Msk;\n",
      "\n",
      "    /* Give valid source address and transfer count and program PDMA memory to memory, dest => CRC_WDATA */\n",
      "    PDMA->CHCTL = (1 << 0); // use PDMA CH0\n",
      "    DMA_DESC[0].ctl =\n",
      "        (1 << PDMA_DSCT_CTL_OPMODE_Pos)  | (0 << PDMA_DSCT_CTL_TXTYPE_Pos) |\n",
      "        (7 << PDMA_DSCT_CTL_BURSIZE_Pos) |\n",
      "        (0 << PDMA_DSCT_CTL_SAINC_Pos)   | (3 << PDMA_DSCT_CTL_DAINC_Pos) |\n",
      "        (2 << PDMA_DSCT_CTL_TXWIDTH_Pos) | (((u32Size / 4) - 1) << PDMA_DSCT_CTL_TXCNT_Pos);\n",
      "    DMA_DESC[0].src = (uint32_t)u32Address;\n",
      "    DMA_DESC[0].dest = (uint32_t) & (CRC->DAT);\n",
      "    DMA_DESC[0].offset = 0;\n",
      "\n",
      "    PDMA->DSCT[0].CTL = PDMA_OP_SCATTER;\n",
      "    PDMA->DSCT[0].NEXT = (uint32_t)&DMA_DESC[0] - (PDMA->SCATBA);\n",
      "\n",
      "    status = PDMA->INTSTS;\n",
      "    PDMA->INTSTS = status;\n",
      "    PDMA->INTEN = (1 << 0);\n",
      "\n",
      "    /* Trigger PDMA CH0 transfer... */\n",
      "    PDMA->SWREQ = (1 << 0);\n",
      "\n",
      "    for (u32LenCnt = 0; u32LenCnt < PDMA_TEST_LENGTH; u32LenCnt++)\n",
      "    {\n",
      "        if (g_au8RxBuffer[u32LenCnt]!= u32LenCnt)\n",
      "        {\n",
      "            printf(\"\\n Receive Data Compare Error!!\");\n",
      "\n",
      "            while (1);\n",
      "        }\n",
      "\n",
      "        g_au8RxBuffer[u32LenCnt] = 0xff;\n",
      "    }\n",
      "\n",
      "    printf(\"\\nUART PDMA test Pass.\\n\");\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "Note that this code is for the M251 series of microcontrollers, and may need to be modified for other series. Additionally, the `SYS_Init()` and `UART0_Init()` functions are not defined in this code snippet, and should be defined elsewhere in your project.\n"
     ]
    }
   ],
   "source": [
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311265ab-1b08-420c-a31b-78acabb59962",
   "metadata": {},
   "source": [
    "## Another choose load_qa_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c491388-dbee-4bc1-b976-d7ff61768595",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Docs Retriever\n",
    "#retriever=vectorstore.as_retriever(search_type=\"mmr\", # Also test \"similarity\"\n",
    "#                                   search_kwargs={\"k\": 8})\n",
    "retriever=vectorstore.as_retriever(search_type=\"similarity\", # Also test \"similarity\"\n",
    "                                   search_kwargs={\"k\": 8})\n",
    "\n",
    "# question & vector search\n",
    "question = \"Write a C code of ACMP comparing DAC output with ACMP1_P1\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "# Chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=QA_CHAIN_PROMPT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c722a9f-1700-49de-af4c-fff778ce44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain({\"input_documents\": docs, \"question\": question}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d137a6b2-6718-45d3-a06a-472a5f68ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docs))\n",
    "print(result['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d23aabb-6d4a-404f-9d58-48c6898d8e91",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53abc44-56e6-4427-b83d-3dec322a5721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm,memory_key=\"chat_history\",return_messages=True)\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=vectorstore.as_retriever(), memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2be885-d6f7-4ebb-8c68-68a192a37c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"Write a C code of ACMP comparing DAC output with ACMP1_P1\"\n",
    "#query = \"Write a C code of BMC data transfer with PDMA\"\n",
    "#query = \"Write a C code function that reverse a string, input a string in parameter and return the reversed string\"\n",
    "query = \"Give me a C code of configure BMC example\"\n",
    "result = qa(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba7747-da00-4b90-922d-43ac0a90f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
